{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12772826,"sourceType":"datasetVersion","datasetId":8074803},{"sourceId":12774920,"sourceType":"datasetVersion","datasetId":8076212},{"sourceId":522723,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":410875,"modelId":428718}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport time\nimport io\nimport base64\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom PIL import Image\nfrom io import BytesIO\n\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score, roc_curve, auc\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom torchvision import transforms\nimport timm\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nimport io\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom sklearn.ensemble import IsolationForest\nimport matplotlib.pyplot as plt\nimport timm\nimport torch.nn as nn\n\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n\nimport os\nimport numpy as np\nimport torch\nfrom tqdm import tqdm\n\nfrom sklearn.metrics import (\n    accuracy_score,\n    precision_score,\n    recall_score,\n    f1_score,\n    balanced_accuracy_score,\n    confusion_matrix,\n    roc_auc_score\n)\n\nfrom sklearn.metrics import precision_recall_curve\n\nfrom sklearn.metrics import precision_score, recall_score, fbeta_score\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-16T02:38:16.206626Z","iopub.execute_input":"2025-08-16T02:38:16.207138Z","iopub.status.idle":"2025-08-16T02:38:28.024503Z","shell.execute_reply.started":"2025-08-16T02:38:16.207114Z","shell.execute_reply":"2025-08-16T02:38:28.023971Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"df_tab_results = pd.read_csv(\"/kaggle/input/new-datasets/tabular_preds.csv\")\ndf_tab_results.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T02:38:28.025542Z","iopub.execute_input":"2025-08-16T02:38:28.025773Z","iopub.status.idle":"2025-08-16T02:38:29.733629Z","shell.execute_reply.started":"2025-08-16T02:38:28.025748Z","shell.execute_reply":"2025-08-16T02:38:29.733019Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0   lgbm_42   lgbm_52   lgbm_62   lgbm_72   lgbm_82  ensemble  \\\n0           0  0.015197  0.012859  0.018430  0.014540  0.013881  0.014981   \n1           1  0.994896  0.994877  0.994858  0.994904  0.994728  0.994852   \n2           2  0.009457  0.008784  0.008883  0.007815  0.008454  0.008679   \n3           3  0.017314  0.013926  0.014249  0.014940  0.013991  0.014884   \n4           4  0.203507  0.222469  0.274706  0.196490  0.217909  0.223016   \n\n   target       isic_id  \n0       0  ISIC_0015670  \n1       0  ISIC_0015845  \n2       0  ISIC_0015864  \n3       0  ISIC_0015902  \n4       0  ISIC_0024200  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>lgbm_42</th>\n      <th>lgbm_52</th>\n      <th>lgbm_62</th>\n      <th>lgbm_72</th>\n      <th>lgbm_82</th>\n      <th>ensemble</th>\n      <th>target</th>\n      <th>isic_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.015197</td>\n      <td>0.012859</td>\n      <td>0.018430</td>\n      <td>0.014540</td>\n      <td>0.013881</td>\n      <td>0.014981</td>\n      <td>0</td>\n      <td>ISIC_0015670</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.994896</td>\n      <td>0.994877</td>\n      <td>0.994858</td>\n      <td>0.994904</td>\n      <td>0.994728</td>\n      <td>0.994852</td>\n      <td>0</td>\n      <td>ISIC_0015845</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.009457</td>\n      <td>0.008784</td>\n      <td>0.008883</td>\n      <td>0.007815</td>\n      <td>0.008454</td>\n      <td>0.008679</td>\n      <td>0</td>\n      <td>ISIC_0015864</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0.017314</td>\n      <td>0.013926</td>\n      <td>0.014249</td>\n      <td>0.014940</td>\n      <td>0.013991</td>\n      <td>0.014884</td>\n      <td>0</td>\n      <td>ISIC_0015902</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.203507</td>\n      <td>0.222469</td>\n      <td>0.274706</td>\n      <td>0.196490</td>\n      <td>0.217909</td>\n      <td>0.223016</td>\n      <td>0</td>\n      <td>ISIC_0024200</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"df_images = pd.read_pickle(\"/kaggle/input/new-datasets/images_w.pkl\")\ndf_images.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T02:38:29.734314Z","iopub.execute_input":"2025-08-16T02:38:29.734548Z","iopub.status.idle":"2025-08-16T02:38:39.684062Z","shell.execute_reply.started":"2025-08-16T02:38:29.734521Z","shell.execute_reply":"2025-08-16T02:38:39.683425Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"        isic_id                                         jpeg_bytes  labels\n0  ISIC_0015670  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...       0\n1  ISIC_0015845  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...       0\n2  ISIC_0015864  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...       0\n3  ISIC_0015902  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...       0\n4  ISIC_0024200  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...       0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>isic_id</th>\n      <th>jpeg_bytes</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_0015670</td>\n      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_0015845</td>\n      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_0015864</td>\n      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ISIC_0015902</td>\n      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ISIC_0024200</td>\n      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T02:38:39.685385Z","iopub.execute_input":"2025-08-16T02:38:39.685604Z","iopub.status.idle":"2025-08-16T02:38:39.775332Z","shell.execute_reply.started":"2025-08-16T02:38:39.685587Z","shell.execute_reply":"2025-08-16T02:38:39.774740Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"image_size = 224\n\ndata_transforms = transforms.Compose([\n    transforms.Resize((image_size, image_size)),\n    transforms.RandomHorizontalFlip(p=0.5),  # simple augmentations\n    transforms.RandomVerticalFlip(p=0.2),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean=[0.485, 0.456, 0.406],  # ImageNet mean\n        std=[0.229, 0.224, 0.225]    # ImageNet std\n    ),\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T02:38:39.776103Z","iopub.execute_input":"2025-08-16T02:38:39.776337Z","iopub.status.idle":"2025-08-16T02:38:39.787523Z","shell.execute_reply.started":"2025-08-16T02:38:39.776319Z","shell.execute_reply":"2025-08-16T02:38:39.786788Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class JpegBytesDataset(Dataset):\n    def __init__(self, df, image_col='jpeg_bytes', label_col='labels', id_col='isic_id', transform=None):\n        \"\"\"\n        Args:\n            df (pd.DataFrame): DataFrame containing the data.\n            image_col (str): Name of the column with image bytes (or base64 strings).\n            label_col (str): Name of the column with labels.\n            id_col (str): Name of the column with unique sample IDs.\n            transform (callable, optional): Optional transform to be applied on a sample.\n        \"\"\"\n        self.df = df.reset_index(drop=True)\n        self.image_col = image_col\n        self.label_col = label_col\n        self.id_col = id_col  # Added id_col attribute\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        # --- Get Image and Label (same as before) ---\n        jpeg_bytes = self.df.iloc[idx][self.image_col]\n\n        # Decode base64 if it's a string\n        if isinstance(jpeg_bytes, str):\n            image_data = base64.b64decode(jpeg_bytes)\n        else:\n            image_data = jpeg_bytes\n\n        image = Image.open(io.BytesIO(image_data)).convert('RGB')\n\n        if self.transform:\n            image = self.transform(image)\n\n        label = self.df.iloc[idx][self.label_col]\n\n        # --- Get the unique ID ---\n        item_id = self.df.iloc[idx][self.id_col]\n\n        # Return all three items\n        return image, label, item_id","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T02:38:39.788245Z","iopub.execute_input":"2025-08-16T02:38:39.788463Z","iopub.status.idle":"2025-08-16T02:38:39.795925Z","shell.execute_reply.started":"2025-08-16T02:38:39.788447Z","shell.execute_reply":"2025-08-16T02:38:39.795263Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import torch\nimport timm\nimport torch.nn as nn\n\n# --- 1. Define your model architecture (exactly as you did) ---\nmodel = timm.create_model(\"eva02_base_patch14_224.mim_in22k\", pretrained=False) # Use pretrained=False if loading a full checkpoint\n\n# Freeze all parameters initially\nfor param in model.parameters():\n    param.requires_grad = False\n\n# Replace the 'head' (classifier) with a new layer\nin_features = model.num_features\nmodel.head = nn.Linear(in_features, 2)\n\n# Unfreeze the layers you intend to train\nfor param in model.head.parameters():\n    param.requires_grad = True\n\nif hasattr(model, \"blocks\") and len(model.blocks) >= 2:\n    for param in model.blocks[-2].parameters():\n        param.requires_grad = True\n\n# --- 2. Load your saved weights ---\n# Define the path to your weights file\nWEIGHTS_PATH = '/kaggle/input/final_img_models/tensorflow2/default/1/eva02_final2.pth' # <--- IMPORTANT: Change this to your file path\n\n# Load the state dictionary from the file\n# Use map_location to ensure it loads correctly whether you're on CPU or GPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ncheckpoint = torch.load(WEIGHTS_PATH, map_location=device)\n\n# --- 3. Apply the weights to your model ---\n# Use strict=False to ignore layers that don't match (like your new 'head')\n# This is the most common and flexible approach for fine-tuning.\nmodel.load_state_dict(checkpoint, strict=False)\n\n# Optional: Set the model to evaluation mode\nmodel.eval()\n\nprint(\"Custom weights loaded successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T02:38:39.796570Z","iopub.execute_input":"2025-08-16T02:38:39.796816Z","iopub.status.idle":"2025-08-16T02:38:43.555349Z","shell.execute_reply.started":"2025-08-16T02:38:39.796793Z","shell.execute_reply":"2025-08-16T02:38:43.554503Z"}},"outputs":[{"name":"stdout","text":"Custom weights loaded successfully!\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"model = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T02:38:43.556277Z","iopub.execute_input":"2025-08-16T02:38:43.556780Z","iopub.status.idle":"2025-08-16T02:38:43.655667Z","shell.execute_reply.started":"2025-08-16T02:38:43.556739Z","shell.execute_reply":"2025-08-16T02:38:43.654965Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"val_dataset = JpegBytesDataset(df_images, transform=data_transforms)\n\nval_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=2, pin_memory=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T02:38:43.656741Z","iopub.execute_input":"2025-08-16T02:38:43.657364Z","iopub.status.idle":"2025-08-16T02:38:43.681915Z","shell.execute_reply.started":"2025-08-16T02:38:43.657343Z","shell.execute_reply":"2025-08-16T02:38:43.681112Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport pandas as pd\nfrom tqdm.auto import tqdm\n\n# Assuming 'model', 'val_loader', and the 'device' are already defined\n\n# --- Evaluation Loop to Get Predictions and IDs ---\nmodel.eval()\nall_preds = []\nall_ids = [] # List to store the IDs\n\n# Use torch.no_grad() for inference\nwith torch.no_grad():\n    # Unpack all three items: inputs, labels (ignored), and ids\n    for inputs, _, ids in tqdm(val_loader, desc=\"Generating Predictions\"):\n        \n        # Move inputs to the correct device\n        inputs = inputs.to(device)\n        \n        # Get model outputs (logits)\n        outputs = model(inputs)\n        \n        # Convert logits to probabilities (for the positive class)\n        probs = torch.softmax(outputs, dim=1)[:, 1]\n        \n        # Append batch predictions and IDs to their respective lists\n        all_preds.append(probs.cpu().numpy())\n        all_ids.extend(ids) # Use extend for IDs, which are often not tensors\n\n# --- Create a New DataFrame for Comparison ---\n\n# Concatenate the list of prediction arrays into a single NumPy array\npredictions_array = np.concatenate(all_preds)\n\n# Create a new DataFrame with the collected IDs and their corresponding predictions\nresults_df = pd.DataFrame({\n    'id': all_ids,\n    'prediction': predictions_array\n})\n\n# Display the first few rows of the new results DataFrame\nprint(\"--- Prediction Results ---\")\nprint(results_df.head())\n\n# You can now easily merge this with your original DataFrame if needed\n# original_df_with_preds = df_image.merge(results_df, on='id')\n# print(\"\\n--- Original DataFrame with Predictions ---\")\n# print(original_df_with_preds.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T02:38:43.683586Z","iopub.execute_input":"2025-08-16T02:38:43.683814Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating Predictions:   0%|          | 0/6267 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9471bddc89cd4b66994cb3c28d939e26"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"results_df.to_pickle(\"eva02_02_preds.pkl\")  # preserves raw bytes safely","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}